{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_lstm_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oe1FTawUffC5"
      },
      "source": [
        "# Hyperparams and Helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JvNGzXEy7H2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "761d5df8-4c2d-4622-b73f-bd23339f53f4"
      },
      "source": [
        "!wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\"\n",
        "!gunzip GoogleNews-vectors-negative300.bin.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-26 17:19:48--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.204.104\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.204.104|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  16.3MB/s    in 99s     \n",
            "\n",
            "2021-10-26 17:21:28 (15.9 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWLocJQsNqoT"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import itertools\n",
        "\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from gensim.models import KeyedVectors\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "random.seed(517)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMwYoWs8Ns-S"
      },
      "source": [
        "# Global Path Vairables\n",
        "ROOT_DIR =  \"drive/MyDrive/DecorAssist/\"\n",
        "DATASET_DIR = ROOT_DIR + \"IKEA/text_data/\"\n",
        "IMAGES_DIR = ROOT_DIR + \"IKEA/images/all_items/\"\n",
        "\n",
        "# Global Parameter Variables\n",
        "MAX_SEQUENCE_LENGTH = 100\n",
        "NUM_WORDS_TOKENIZER = 50000\n",
        "EMBEDDING_DIM = 300\n",
        "BATCH_SIZE = 16\n",
        "POSITIVE_SIZE = 300 # We might only use a subset of the positive pairs\n",
        "TRAIN_TEST_RATIO = 0.33\n",
        "\n",
        "# Model Hyperparameters\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "LEARNING_RATE = 2e-4 # 0.001\n",
        "HIDDEN_DIM = 128 # 64\n",
        "N_LAYERS = 4 # 2\n",
        "EPOCHS = 10\n",
        "CLIP = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKYbhsNmNgzV"
      },
      "source": [
        "def preprocess_img(path):\n",
        "  img = cv2.imread(path)\n",
        "  img = cv2.resize(img, (75, 115))\n",
        "  img = img.astype(np.float32) / 255\n",
        "  return img\n",
        "\n",
        "\n",
        "def read_pickle(fn):\n",
        "\twith open(fn, \"rb\") as f:\n",
        "\t\treturn pickle.load(f)\n",
        "  \n",
        "\n",
        "def random_negative_sampling(all_positive_pairs):\n",
        "  num_examples = len(all_positive_pairs) * 2\n",
        "  all_item_ids = list(set([x[0] for x in all_positive_pairs] + [x[1] for x in all_positive_pairs]))\n",
        "  negative_count = 0\n",
        "  selected_negative_pairs = []\n",
        "  while negative_count < num_examples / 2:\n",
        "    random_pair = tuple(random.sample(all_item_ids, 2))\n",
        "    if random_pair in all_positive_pairs:\n",
        "      continue\n",
        "    else:\n",
        "      selected_negative_pairs.append(random_pair)\n",
        "      negative_count += 1\n",
        "  return selected_negative_pairs\n",
        "\n",
        "\n",
        "def get_embedding_matrix(word_index, weights_path=\"/content/GoogleNews-vectors-negative300.bin\"):\n",
        "  word2vecDict = KeyedVectors.load_word2vec_format(weights_path, binary=True)\n",
        "  embed_size = 300\n",
        "  embeddings_index = dict()\n",
        "  for word in word2vecDict.wv.vocab:\n",
        "    embeddings_index[word] = word2vecDict.word_vec(word)\n",
        "  print(\"Loaded \" + str(len(embeddings_index)) + \" word vectors.\")\n",
        "        \n",
        "  embedding_matrix = 1 * np.random.randn(len(word_index)+1, embed_size)\n",
        "\n",
        "  embeddedCount = 0\n",
        "  for word, i in word_index.items():\n",
        "    i-=1\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None: \n",
        "      embedding_matrix[i] = embedding_vector\n",
        "      embeddedCount+=1\n",
        "  print(\"total embedded:\", embeddedCount, \"common words\")\n",
        "  del(embeddings_index)\n",
        "  return embedding_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LRFmhR8RGJJ"
      },
      "source": [
        "# Build Train and Eval Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJPk6ZK5mSw-"
      },
      "source": [
        "#### Load raw data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaq9zR8RQRIp"
      },
      "source": [
        "# {room image url -> string of room category}; e.g.: 'ikea-town-and-country__1364308377063-s4.jpg': 'Living Room'\n",
        "room_categories = read_pickle(DATASET_DIR + \"categories_dict.p\")\n",
        "# {item image ID -> string of item category}; e.g.: '291.292.29': 'Footstool',\n",
        "item_categories = read_pickle(DATASET_DIR + \"categories_images_dict.p\")\n",
        "# {item image id -> dict of descriptions}; e.g. '202.049.06': {'color': 'Grey,black','desc': 'View more product information Concealed press studs keep the quilt in place','img': 'images/objects/202.049.06.jpg','name': 'GURLI','size': '120x180 cm','type': 'Throw'},\n",
        "item_property = read_pickle(DATASET_DIR + \"products_dict.p\")\n",
        "# {item image url -> {description, name}}; e.g: '/static/images/902.592.50.jpg': {'desc': 'The high pile dampens sound and provides a soft surface to walk on.','name': 'GSER'},\n",
        "item_to_description = read_pickle(DATASET_DIR + \"img_to_desc.p\")\n",
        "# {item image url -> list of corresponding room image url}; e.g.: 'images/001.509.85.jpg': ['images/room_scenes/ikea-wake-up-and-grow__1364335362013-s4.jpg','images/room_scenes/ikea-wake-up-and-grow-1364335370196.jpg'],\n",
        "item_to_rooms_map = read_pickle(DATASET_DIR + \"item_to_room.p\")\n",
        "# {room image url -> list of items}; e.g.: 'ikea-work-from-home-in-perfect-harmony__1364319311386-s4.jpg': ['desk','chair']\n",
        "room_to_item_categories = read_pickle(DATASET_DIR + \"room_to_items.p\")\n",
        "\n",
        "# Some simple preprossing\n",
        "item_to_info = {key : value[\"type\"] + \" \" +\n",
        "                             value[\"desc\"]\n",
        "                       for key, value in item_property.items()} # remove view more info\n",
        "\n",
        "room_to_items = {}\n",
        "\n",
        "for item_url, room_url_list in item_to_rooms_map.items():\n",
        "  item_id = item_url.split(\"/\")[-1].split(\".jpg\")[0]\n",
        "\n",
        "  for room_url in room_url_list:\n",
        "    room_id = room_url.split(\"/\")[-1].split(\".jpg\")[0]\n",
        "    if room_id not in room_to_items:\n",
        "      room_to_items[room_id] = []\n",
        "    else:\n",
        "      room_to_items[room_id].append(item_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDaGXCr4mV0I"
      },
      "source": [
        "#### Construct positive and negative pairs\n",
        "\n",
        "For IR-style problem, seen and unseen can be tricky. We need to discuss whether unseen means \"unseen pairs\" or \"unseen image or text\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0MZqyUWmN87"
      },
      "source": [
        "all_positive_pairs = []\n",
        "for room, item_id_list in room_to_items.items():\n",
        "  pairs_for_current_room = list(itertools.combinations(room_to_items[room], 2)) # n choose 2\n",
        "  all_positive_pairs += pairs_for_current_room\n",
        "\n",
        "all_positive_pairs = all_positive_pairs[:POSITIVE_SIZE]\n",
        "all_pairs = all_positive_pairs + random_negative_sampling(all_positive_pairs)\n",
        "y = np.array([np.array([1, 0]) for _ in range(len(all_positive_pairs))] + \n",
        "             [np.array([0, 1]) for _ in range(len(all_positive_pairs))])\n",
        "train_pairs, val_paris, y_train, y_val = train_test_split(all_pairs, y, test_size=TRAIN_TEST_RATIO, random_state=517)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRaA0zbGmeyt"
      },
      "source": [
        "#### Build PyTorch dataloader for train/val image/text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uckQwq5lIN82"
      },
      "source": [
        "train_image_premise_id_list = [x[0] for x in train_pairs]\n",
        "train_image_hypothesis_id_list = [x[1] for x in train_pairs]\n",
        "X_train_image_premise = np.array(list(map(lambda image_id: preprocess_img(IMAGES_DIR + image_id + \".jpg\"), train_image_premise_id_list)))\n",
        "X_train_image_hypothesis = np.array(list(map(lambda image_id: preprocess_img(IMAGES_DIR + image_id + \".jpg\"), train_image_hypothesis_id_list)))\n",
        "X_train_image_premise = np.reshape(X_train_image_premise, (X_train_image_premise.shape[0], 3, 75, 115))\n",
        "X_train_image_hypothesis = np.reshape(X_train_image_hypothesis, (X_train_image_hypothesis.shape[0], 3, 75, 115))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ai_e-I4NiFyk"
      },
      "source": [
        "val_image_premise_id_list = [x[0] for x in val_paris]\n",
        "val_image_hypothesis_id_list = [x[1] for x in val_paris]\n",
        "X_val_image_premise = np.array(list(map(lambda image_id: preprocess_img(IMAGES_DIR + image_id + \".jpg\"), val_image_premise_id_list)))\n",
        "X_val_image_hypothesis = np.array(list(map(lambda image_id: preprocess_img(IMAGES_DIR + image_id + \".jpg\"), val_image_hypothesis_id_list)))\n",
        "X_val_image_premise = np.reshape(X_val_image_premise, (X_val_image_premise.shape[0], 3, 75, 115))\n",
        "X_val_image_hypothesis = np.reshape(X_val_image_hypothesis, (X_val_image_hypothesis.shape[0], 3, 75, 115))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lO1ZkgcUK1m7",
        "outputId": "d087a8c0-d1df-4dc1-d28c-0a6d9ca13080"
      },
      "source": [
        "train_premise_texts = [item_to_info[id] for id in train_image_premise_id_list]\n",
        "train_hypothesis_texts = [item_to_info[id] for id in train_image_hypothesis_id_list]\n",
        "tokenizer = Tokenizer(num_words=NUM_WORDS_TOKENIZER, lower=True)\n",
        "tokenizer.fit_on_texts(train_premise_texts + train_hypothesis_texts)\n",
        "WORD_INDEX = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(WORD_INDEX))\n",
        "print('Max len:', MAX_SEQUENCE_LENGTH)\n",
        "WORD2VEC_EMBEDDING_MATRIX = get_embedding_matrix(WORD_INDEX)\n",
        "\n",
        "X_train_text_premise = tokenizer.texts_to_sequences(train_premise_texts)\n",
        "X_train_text_premise = pad_sequences(X_train_text_premise, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "X_train_text_hypothesis = tokenizer.texts_to_sequences(train_hypothesis_texts)\n",
        "X_train_text_hypothesis = pad_sequences(X_train_text_hypothesis, maxlen=MAX_SEQUENCE_LENGTH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 288 unique tokens.\n",
            "Max len: 100\n",
            "Loaded 3000000 word vectors.\n",
            "total embedded: 272 common words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iAakls6kMkX"
      },
      "source": [
        "val_premise_texts = [item_to_info[id] for id in val_image_premise_id_list]\n",
        "val_hypothesis_texts = [item_to_info[id] for id in val_image_hypothesis_id_list]\n",
        "\n",
        "# Please notice that: tokenizer is ONLY used on training set to build vocab\n",
        "X_val_text_premise = tokenizer.texts_to_sequences(val_premise_texts)\n",
        "X_val_text_premise = pad_sequences(X_val_text_premise, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "X_val_text_hypothesis = tokenizer.texts_to_sequences(val_hypothesis_texts)\n",
        "X_val_text_hypothesis = pad_sequences(X_val_text_hypothesis, maxlen=MAX_SEQUENCE_LENGTH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Vm9RcV-MWk7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "692c346f-b0ed-49ef-9e96-c984cc06f065"
      },
      "source": [
        "img_train_data = TensorDataset(torch.from_numpy(X_train_image_premise), torch.from_numpy(X_train_image_hypothesis), torch.from_numpy(y_train))\n",
        "text_train_data = TensorDataset(torch.from_numpy(X_train_text_premise), torch.from_numpy(X_train_text_hypothesis), torch.from_numpy(y_train))\n",
        "\n",
        "img_val_data = TensorDataset(torch.from_numpy(X_val_image_premise), torch.from_numpy(X_val_image_hypothesis), torch.from_numpy(y_val))\n",
        "text_val_data = TensorDataset(torch.from_numpy(X_val_text_premise), torch.from_numpy(X_val_text_hypothesis), torch.from_numpy(y_val))\n",
        "\n",
        "text_train_loader = DataLoader(text_train_data, batch_size=BATCH_SIZE)\n",
        "img_train_loader = DataLoader(img_train_data, batch_size=BATCH_SIZE)\n",
        "\n",
        "text_val_loader = DataLoader(text_val_data, batch_size=BATCH_SIZE)\n",
        "img_val_loader = DataLoader(img_val_data, batch_size=BATCH_SIZE)\n",
        "\n",
        "print(len(text_train_loader), len(img_train_loader))\n",
        "print(len(text_val_loader), len(img_val_loader))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26 26\n",
            "13 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW73L3zZNe1e"
      },
      "source": [
        "# Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_7w-DGAxyiZ"
      },
      "source": [
        "class CNN_LSTM(nn.Module):\n",
        "  def __init__(self, vocab_size, weights_matrix, n_hidden, n_layers, n_out):\n",
        "    super(CNN_LSTM, self).__init__()\n",
        "\n",
        "    # LSTM for the text overview\n",
        "    self.vocab_size, self.n_hidden, self.n_out, self.n_layers = vocab_size, n_hidden, n_out, n_layers\n",
        "    num_embeddings, embedding_dim = weights_matrix.shape[0], weights_matrix.shape[1]\n",
        "    self.emb = nn.Embedding(num_embeddings, embedding_dim)\n",
        "    self.emb.weight.data.copy_(torch.from_numpy(weights_matrix))\n",
        "    self.emb.weight.requires_grad = True\n",
        "    self.lstm = nn.LSTM(embedding_dim, self.n_hidden, self.n_layers, dropout=0.2, batch_first=True)\n",
        "    self.dropout = nn.Dropout(0.1)\n",
        "    self.lstm_fc = nn.Linear(self.n_hidden, 128)\n",
        "    # self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    # CNN for the posters\n",
        "    self.conv1 = nn.Conv2d(3, 32, 3)\n",
        "    self.max_pool1 = nn.MaxPool2d(2)\n",
        "    self.conv2 = nn.Conv2d(32, 64, 3)\n",
        "    self.max_pool2 = nn.MaxPool2d(2)\n",
        "    self.conv3 = nn.Conv2d(64, 128, 3)\n",
        "    self.max_pool3 = nn.MaxPool2d(2)\n",
        "    self.conv4 = nn.Conv2d(128, 128, 3)\n",
        "    self.max_pool4 = nn.MaxPool2d(2)\n",
        "    self.cnn_dropout = nn.Dropout(0.1)\n",
        "    self.cnn_fc = nn.Linear(5*2*128, 512)\n",
        "\n",
        "    # Concat layer for the combined feature space\n",
        "    # self.combined_fc1 = nn.Linear(640, 256)\n",
        "    self.combined_fc1 = nn.Linear(640*2, 256)\n",
        "    self.combined_fc2 = nn.Linear(256, 128)\n",
        "    self.output_fc = nn.Linear(128, n_out)\n",
        "    self.softmax = nn.Softmax()\n",
        "\n",
        "  def lstm_encoder(self, lstm_inp):\n",
        "    batch_size = lstm_inp.size(0)\n",
        "    hidden = self.init_hidden(batch_size)\n",
        "    lstm_inp = lstm_inp.long()\n",
        "    embeds = self.emb(lstm_inp)\n",
        "    lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "    lstm_out = self.dropout(lstm_out[:, -1])\n",
        "    lstm_out = F.relu(self.lstm_fc(lstm_out))\n",
        "    return lstm_out\n",
        "\n",
        "  def cnn_encoder(self, cnn_inp):\n",
        "    x = F.relu(self.conv1(cnn_inp))\n",
        "    x = self.max_pool1(x)\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = self.max_pool2(x)\n",
        "    x = F.relu(self.conv3(x))\n",
        "    x = self.max_pool3(x)\n",
        "    x = F.relu(self.conv4(x))\n",
        "    x = self.max_pool4(x)\n",
        "    x = x.view(-1, 5 * 2 * 128)\n",
        "    x = self.cnn_dropout(x)\n",
        "    cnn_out = F.relu(self.cnn_fc(x))\n",
        "    return cnn_out\n",
        "\n",
        "  def forward(self, lstm_inp1, lstm_inp2, cnn_inp1, cnn_inp2):\n",
        "    cnn_out1, cnn_out2 = self.cnn_encoder(cnn_inp1), self.cnn_encoder(cnn_inp2)\n",
        "    lstm_out1, lstm_out2 = self.lstm_encoder(lstm_inp1), self.lstm_encoder(lstm_inp2)\n",
        "    combined_inp = torch.cat((cnn_out1, cnn_out2, lstm_out1, lstm_out2), 1)\n",
        "    x_comb = F.relu(self.combined_fc1(combined_inp))\n",
        "    x_comb = F.relu(self.combined_fc2(x_comb))\n",
        "    # out = torch.sigmoid(self.output_fc(x_comb))\n",
        "    out = self.softmax(self.output_fc(x_comb))\n",
        "    return out\n",
        "\n",
        "  def init_hidden(self, batch_size):\n",
        "    weight = next(self.parameters()).data\n",
        "    hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device),\n",
        "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device))\n",
        "    return hidden"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX2rumtEQYv8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7bb45ee-4835-4a44-96d4-dafc6108407a"
      },
      "source": [
        "print(\"Currently using device: {}\\n\".format(DEVICE))\n",
        "\n",
        "model = CNN_LSTM(len(WORD_INDEX)+1, WORD2VEC_EMBEDDING_MATRIX, HIDDEN_DIM, N_LAYERS, y.shape[1])\n",
        "model.to(DEVICE)\n",
        "print(\"Model Architecture {}\\n\".format(model))\n",
        "\n",
        "lr= LEARNING_RATE\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
        "\n",
        "print(\"Training Started...\")\n",
        "model.train()\n",
        "for i in range(EPOCHS):\n",
        "  total_acc_train = 0\n",
        "  total_loss_train = 0\n",
        "    \n",
        "  for lstm, cnn in zip(text_train_loader, img_train_loader):\n",
        "    lstm_inp1, lstm_inp2, lstm_labels = lstm\n",
        "    cnn_inp1, cnn_inp2, cnn_labels = cnn\n",
        "    lstm_inp1, lstm_inp2, lstm_labels = lstm_inp1.to(DEVICE), lstm_inp2.to(DEVICE), lstm_labels.to(DEVICE)\n",
        "    cnn_inp1, cnn_inp2, cnn_labels = cnn_inp1.to(DEVICE), cnn_inp2.to(DEVICE), cnn_labels.to(DEVICE)\n",
        "    model.zero_grad()\n",
        "    output = model(lstm_inp1, lstm_inp2, cnn_inp1, cnn_inp2)\n",
        "    loss = criterion(output.squeeze(), lstm_labels.float())\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n",
        "    optimizer.step()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      acc = torch.abs(output.squeeze() - lstm_labels.float()).view(-1)\n",
        "      acc = (1. - acc.sum() / acc.size()[0])\n",
        "      total_acc_train += acc\n",
        "      total_loss_train += loss.item()\n",
        "  \n",
        "  train_acc = total_acc_train/len(text_train_loader)\n",
        "  train_loss = total_loss_train/len(text_train_loader)\n",
        "  model.eval()\n",
        "  total_acc_val = 0\n",
        "  total_loss_val = 0\n",
        "  with torch.no_grad():\n",
        "    for lstm, cnn in zip(text_val_loader, img_val_loader):\n",
        "      lstm_inp1, lstm_inp2, lstm_labels = lstm\n",
        "      cnn_inp1, cnn_inp2, cnn_labels = cnn\n",
        "      lstm_inp1, lstm_inp2, lstm_labels = lstm_inp1.to(DEVICE), lstm_inp2.to(DEVICE), lstm_labels.to(DEVICE)\n",
        "      cnn_inp1, cnn_inp2, cnn_labels = cnn_inp1.to(DEVICE), cnn_inp2.to(DEVICE), cnn_labels.to(DEVICE)\n",
        "      model.zero_grad()\n",
        "      output = model(lstm_inp1, lstm_inp2, cnn_inp1, cnn_inp2)\n",
        "      val_loss = criterion(output.squeeze(), lstm_labels.float())\n",
        "      acc = torch.abs(output.squeeze() - lstm_labels.float()).view(-1)\n",
        "      acc = (1. - acc.sum() / acc.size()[0])\n",
        "      total_acc_val += acc\n",
        "      total_loss_val += val_loss.item()\n",
        "  val_acc = total_acc_val/len(text_val_loader)\n",
        "  val_loss = total_loss_val/len(text_val_loader)\n",
        "  print(f'Epoch {i+1}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | val_loss: {val_loss:.4f} val_acc: {val_acc:.4f}')\n",
        "  model.train()\n",
        "  torch.cuda.empty_cache()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Currently using device: cuda\n",
            "\n",
            "Model Architecture CNN_LSTM(\n",
            "  (emb): Embedding(289, 300)\n",
            "  (lstm): LSTM(300, 128, num_layers=4, batch_first=True, dropout=0.2)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (lstm_fc): Linear(in_features=128, out_features=128, bias=True)\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (max_pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (max_pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (max_pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (max_pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (cnn_dropout): Dropout(p=0.1, inplace=False)\n",
            "  (cnn_fc): Linear(in_features=1280, out_features=512, bias=True)\n",
            "  (combined_fc1): Linear(in_features=1280, out_features=256, bias=True)\n",
            "  (combined_fc2): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (output_fc): Linear(in_features=128, out_features=2, bias=True)\n",
            "  (softmax): Softmax(dim=None)\n",
            ")\n",
            "\n",
            "Training Started...\n",
            "Epoch 1: train_loss: 0.6941 train_acc: 0.4995 | val_loss: 0.6931 val_acc: 0.5000\n",
            "Epoch 2: train_loss: 0.6933 train_acc: 0.4999 | val_loss: 0.6932 val_acc: 0.5000\n",
            "Epoch 3: train_loss: 0.6931 train_acc: 0.5000 | val_loss: 0.6931 val_acc: 0.5000\n",
            "Epoch 4: train_loss: 0.6916 train_acc: 0.5008 | val_loss: 0.6920 val_acc: 0.5008\n",
            "Epoch 5: train_loss: 0.6846 train_acc: 0.5053 | val_loss: 0.6903 val_acc: 0.5040\n",
            "Epoch 6: train_loss: 0.6715 train_acc: 0.5172 | val_loss: 0.6974 val_acc: 0.5108\n",
            "Epoch 7: train_loss: 0.6506 train_acc: 0.5368 | val_loss: 0.6955 val_acc: 0.5169\n",
            "Epoch 8: train_loss: 0.6292 train_acc: 0.5577 | val_loss: 0.6967 val_acc: 0.5268\n",
            "Epoch 9: train_loss: 0.6132 train_acc: 0.5780 | val_loss: 0.7088 val_acc: 0.5283\n",
            "Epoch 10: train_loss: 0.5928 train_acc: 0.5869 | val_loss: 0.6933 val_acc: 0.5547\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JRkG-JWjfCj"
      },
      "source": [
        "# Ranker\n",
        "- For image 1 image 2 text 1 text 2 as input, we generate a score ~(0,1).\n",
        "- Search engine: only given one image and one text, compute the score for this item with all the other items in the pool. E.g, if we have num_items, the score matrix will be (num_items, ). Find predicted top 5 or top 10.\n",
        "- Haocheng's ranking evaluation: for a specific item, we know all the ground truth items that are in the same room as this specific item. \n",
        "\n",
        "The output from yuanxin: {\"802.903.9234.923\" : score, xxx}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvOlqTLXknYN"
      },
      "source": [
        "def single_pair_inference(premise_image_path, hypothesis_image_path, premise_text, hypothesis_text, model, tokenizer, is_plot=False):\n",
        "  premise_sequence = tokenizer.texts_to_sequences([premise_text])\n",
        "  premise_sequence = pad_sequences(premise_sequence, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "  hypothesis_sequence = tokenizer.texts_to_sequences([hypothesis_text])\n",
        "  hypothesis_sequence = pad_sequences(hypothesis_sequence, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "  image_premise, image_hypothesis = preprocess_img(premise_image_path), preprocess_img(hypothesis_image_path)\n",
        "\n",
        "  if is_plot:\n",
        "    fig = plt.figure(figsize=(15, 15))\n",
        "    ax1 = fig.add_subplot(2,2,1)\n",
        "    ax1.imshow(image_premise)\n",
        "    ax2 = fig.add_subplot(2,2,2)\n",
        "    ax2.imshow(image_hypothesis)\n",
        "    print(\"Left item description ------ {}\".format(premise_text))\n",
        "    print(\"Right item description ------  {}\".format(hypothesis_text))\n",
        "\n",
        "\n",
        "  image_premise = np.reshape(image_premise, (1, 3, 75, 115))\n",
        "  image_hypothesis = np.reshape(image_hypothesis, (1, 3, 75, 115))\n",
        "\n",
        "  img_data = TensorDataset(torch.from_numpy(image_premise), torch.from_numpy(image_hypothesis))\n",
        "  text_data = TensorDataset(torch.from_numpy(premise_sequence), torch.from_numpy(hypothesis_sequence))\n",
        "  \n",
        "  text_loader = DataLoader(text_data, batch_size=1)\n",
        "  img_loader = DataLoader(img_data, batch_size=1)\n",
        "\n",
        "  for lstm, cnn in zip(text_loader, img_loader):\n",
        "    lstm_inp1, lstm_inp2 = lstm\n",
        "    cnn_inp1, cnn_inp2 = cnn\n",
        "    lstm_inp1, lstm_inp2 = lstm_inp1.to(DEVICE), lstm_inp2.to(DEVICE)\n",
        "    cnn_inp1, cnn_inp2 = cnn_inp1.to(DEVICE), cnn_inp2.to(DEVICE)\n",
        "    model.zero_grad()\n",
        "    output = model(lstm_inp1, lstm_inp2, cnn_inp1, cnn_inp2)\n",
        "\n",
        "  return output.squeeze().cpu().detach().numpy().tolist()\n"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "ft7vTrP2EEGa",
        "outputId": "6f16cb2f-0d89-4602-a9b0-5c2b8c703173"
      },
      "source": [
        "random_index = random.randint(0, len(train_image_premise_id_list))\n",
        "image_id_1 = train_image_premise_id_list[random_index]\n",
        "image_id_2 = train_image_hypothesis_id_list[random_index]\n",
        "text_1 = train_premise_texts[random_index]\n",
        "text_2 = train_hypothesis_texts[random_index]\n",
        "score = single_pair_inference(premise_image_path=IMAGES_DIR + image_id_1 + \".jpg\",\n",
        "          hypothesis_image_path=IMAGES_DIR + image_id_2 + \".jpg\",\n",
        "          premise_text=text_1,\n",
        "          hypothesis_text=text_2,\n",
        "          model=model,\n",
        "          tokenizer=tokenizer,\n",
        "          is_plot=True)\n",
        "print(\"Actual Label for this pair is \", y_train[random_index])\n",
        "print(\"The predicted scores are \", score)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Left item description ------ Bed tent with curtain \n",
            "Right item description ------  Balancing bench Helps your child to develop coordination, balance and concentration.\n",
            "Actual Label for this pair is  [0 1]\n",
            "The predicted scores are  [0.1311706155538559, 0.8688294291496277]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x1080 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0qmvz0xpmci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7357c58-972c-4207-8ec8-b26d7d3b30bc"
      },
      "source": [
        "def ranker(input_image_id, input_description, all_ids):\n",
        "  # for id in all_id, get image, get description, input to single_pair_inference\n",
        "  # \n",
        "  pass"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "600"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck31vLsy5Mth"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}